import streamlit as st
import os
from azure.core.credentials import AzureKeyCredential
from azure.ai.documentintelligence import DocumentIntelligenceClient
from dotenv import load_dotenv
from chat_response import generate_response
from asset_judge import asset_judge, parse_llm_output_to_dataframe
from asset_extract_items import asset_extract_items
from make_df import parse_extracted_items_to_dataframe, parse_llm_output_to_dataframe
from refine_rag_response_from_df import refine_rag_response_from_df 
import pandas as pd


# .envã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
AZURE_ENDPOINT = os.getenv("DOC_ENDPOINT")
AZURE_KEY = os.getenv("DOC_API_KEY")

st.set_page_config(page_title="å›ºå®šè³‡ç”£åˆ¤å®šã‚¢ãƒ—ãƒª", layout="wide")
st.title("å›ºå®šè³‡ç”£åˆ¤å®šã‚¢ãƒ—ãƒª")

# --- docs_for_indexã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º ---
docs_dir = "document/docs_for_index"
if not os.path.exists(docs_dir):
    os.makedirs(docs_dir, exist_ok=True)
docs_files = os.listdir(docs_dir)
# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º ---
st.sidebar.subheader("docs_for_indexå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
if docs_files:
    for f in docs_files:
        file_path = os.path.join(docs_dir, f)
        col1, col2 = st.sidebar.columns([3, 1])
        with col1:
            st.write(f"- {f}")
        with col2:
            if st.button("å‰Šé™¤", key=f"delete_index_{f}"):
                os.remove(file_path)
                st.experimental_rerun()
else:
    st.sidebar.write("ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# --- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†ä½œæˆç”¨PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã¸ç§»å‹•ï¼‰ ---
st.sidebar.subheader("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†ä½œæˆç”¨PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_index_file = st.sidebar.file_uploader("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆdocs_for_indexã«ä¿å­˜ï¼‰", type=["pdf"], key="index_pdf")
if uploaded_index_file is not None:
    save_path = os.path.join(docs_dir, uploaded_index_file.name)
    with open(save_path, "wb") as f:
        f.write(uploaded_index_file.read())
    st.sidebar.success(f"{uploaded_index_file.name} ã‚’ docs_for_index ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

# --- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†ä½œæˆãƒœã‚¿ãƒ³ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã¸ç§»å‹•ï¼‰ ---
import subprocess, sys
if st.sidebar.button("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†ä½œæˆ"):
    with st.spinner("FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†ä½œæˆä¸­..."):
        try:
            result = subprocess.run(
                # sys.executable ã¯ã€Œã„ã¾å‹•ã„ã¦ã„ã‚‹ä»®æƒ³ç’°å¢ƒã® Python ã€
                [sys.executable, "faiss_index_builder.py"],
                capture_output=True, text=True, check=True
            )
            st.sidebar.success("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            st.sidebar.text_area("å‡ºåŠ›ãƒ­ã‚°", result.stdout + "\n" + result.stderr, height=200)
        except subprocess.CalledProcessError as e:
            st.sidebar.error("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            st.sidebar.text_area("ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°", e.stdout + "\n" + e.stderr, height=200)

st.sidebar.markdown("---")

doc_uploaded_example_accounting_entry_dir = "document/example_accounting_entry"
st.sidebar.subheader("ä»•è¨³ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_example_accounting_entry = st.sidebar.file_uploader("ä»•è¨³ä¾‹ã‚’ä¿å­˜ã—å­¦ç¿’ã™ã‚‹", type=["pdf","xlsx", "xls"], key="accounting_entry")
if uploaded_example_accounting_entry is not None:
    save_path = os.path.join(doc_uploaded_example_accounting_entry_dir, uploaded_example_accounting_entry.name)
    with open(save_path, "wb") as f:
        f.write(uploaded_example_accounting_entry.read())
    st.sidebar.success(f"{uploaded_example_accounting_entry.name} ã‚’ example_accounting_entry ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

# --- å¯¾ã«ãªã‚‹è¨¼æ†‘ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ ---
st.sidebar.subheader("é–¢é€£è¨¼æ†‘ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_example_accounting_entry = st.sidebar.file_uploader("å¯¾ã«ãªã‚‹è¨¼æ†‘ã‚’ã“ã¡ã‚‰ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf","xlsx", "xls"], key="accounting_entry2")
if uploaded_example_accounting_entry is not None:
    save_path = os.path.join(doc_uploaded_example_accounting_entry_dir, uploaded_example_accounting_entry.name)
    with open(save_path, "wb") as f:
        f.write(uploaded_example_accounting_entry.read())
    st.sidebar.success(f"{uploaded_example_accounting_entry.name} ã‚’ example_accounting_entry ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

st.sidebar.subheader("example_accounting_entryå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
docs_uploaded_example_accounting_entry_files = os.listdir(doc_uploaded_example_accounting_entry_dir)

if docs_uploaded_example_accounting_entry_files:
    for filename in docs_uploaded_example_accounting_entry_files:
        file_path = os.path.join(doc_uploaded_example_accounting_entry_dir, filename)
        col1, col2 = st.sidebar.columns([3, 1])
        with col1:
            st.write(f"- {filename}")
        with col2:
            if st.button("å‰Šé™¤", key=f"delete_{filename}"):
                os.remove(file_path)
                st.experimental_rerun()  # å‰Šé™¤å¾Œã«ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦è¡¨ç¤ºæ›´æ–°
else:
    st.sidebar.write("ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


# --- è³ªå•ç”¨PDF/ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ ---
st.subheader("è¨¼æ†‘PDF/ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_qa_file = st.file_uploader(
    "å›ºå®šè³‡ç”£åˆ¤å®šã‚’è¡Œã„ãŸã„è¨¼æ†‘ã®PDFã¾ãŸã¯ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
    type=["pdf", "jpg", "jpeg", "png", "bmp", "tiff"],
    key="qa_pdf"
)

# PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã¿è§£æã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
if uploaded_qa_file is not None and "qa_file_name" not in st.session_state:
    try:
        with st.spinner("PDFã‚’è§£æä¸­..."):
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            with open("temp_upload.pdf", "wb") as f:
                f.write(uploaded_qa_file.read())

            # Azure Document Intelligenceã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
            client = DocumentIntelligenceClient(
                endpoint=AZURE_ENDPOINT,
                credential=AzureKeyCredential(AZURE_KEY)
            )

            # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦é€ä¿¡
            with open("temp_upload.pdf", "rb") as doc:
                poller = client.begin_analyze_document(
                    "prebuilt-layout",
                    doc,
                    output_content_format="markdown",
                    content_type="application/octet-stream",
                )
                result = poller.result()

            # --- å–å¾—ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’ç¢ºèª ---
            import json
            from pprint import pformat

            def safe_obj_to_dict(obj):
                # Azure SDKã®ãƒ¢ãƒ‡ãƒ«ã¯__dict__ã‚„vars()ã§å±æ€§ã‚’å–å¾—ã§ãã‚‹
                try:
                    return {k: safe_obj_to_dict(v) if hasattr(v, "__dict__") else v for k, v in vars(obj).items()}
                except Exception:
                    return str(obj)

            # --- ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ãŒã‚ã‚Œã°pandas.DataFrameã§è¡¨ç¤º ---
            import pandas as pd
            # --- æ§‹é€ ã‚’æŒã£ãŸãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦paragraphsã¨tablesã‚’çµ±åˆ ---
            def extract_structured_text(result):
                texts = []

                # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’Markdownå½¢å¼ã§æŠ½å‡º
                tables = getattr(result, "tables", [])
                for table in tables:
                    nrows = table.row_count
                    ncols = table.column_count
                    cells = [["" for _ in range(ncols)] for _ in range(nrows)]
                    for cell in table.cells:
                        r, c = cell.row_index, cell.column_index
                        cells[r][c] = cell.content
                    # Markdownãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼
                    if nrows > 0 and ncols > 0:
                        header = "| " + " | ".join(cells[0]) + " |"
                        sep = "| " + " | ".join(["---"] * ncols) + " |"
                        body = "\n".join(["| " + " | ".join(row) + " |" for row in cells[1:]])
                        table_md = "\n".join([header, sep, body])
                        texts.append(table_md)

                # æ®µè½æƒ…å ±ã‚’éšå±¤ä»˜ãã§æŠ½å‡º
                paragraphs = getattr(result, "paragraphs", [])
                for para in paragraphs:
                    # heading_levelãŒã‚ã‚Œã°è¦‹å‡ºã—ã¨ã—ã¦å‡ºåŠ›
                    heading_level = getattr(para, "role", None)
                    if heading_level and hasattr(para, "content"):
                        texts.append(f"## {para.content}")
                    else:
                        texts.append(para.content)

                return "\n\n".join(texts)

            extracted_text = extract_structured_text(result)


            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.session_state["extracted_text"] = extracted_text
            st.session_state["qa_file_name"] = uploaded_qa_file.name

            # LLMå‡¦ç†ï¼ˆè‡ªå‹•å®Ÿè¡Œï¼‰
            with st.spinner("LLMã§å“ç›®ã¨é‡‘é¡ã‚’æŠ½å‡ºä¸­..."):
                extracted_result = asset_extract_items(extracted_text)
                st.session_state["extracted_items"] = extracted_result

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.remove("temp_upload.pdf")
    except Exception as e:
        import traceback
        error_message = "PDFè§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n" + traceback.format_exc()
        st.error(error_message)
if "extracted_items" in st.session_state:
    st.subheader("LLMã«ã‚ˆã‚‹å“ç›®ãƒ»é‡‘é¡æŠ½å‡ºçµæœ")
    # st.markdown(st.session_state["extracted_text"])
    try:
        df_extracted = parse_extracted_items_to_dataframe(st.session_state["extracted_items"])
        # st.subheader("æŠ½å‡ºçµæœï¼ˆè¡¨å½¢å¼ï¼‰")
        edited_df_extracted = st.data_editor(df_extracted, use_container_width=True, num_rows="dynamic")

        # ä¿å­˜ãƒœã‚¿ãƒ³ï¼ˆä»»æ„ï¼‰
        if st.button("æŠ½å‡ºçµæœã®ä¿®æ­£ã‚’ä¿å­˜"):
            st.session_state["edited_extracted_df"] = edited_df_extracted
            st.success("ä¿®æ­£ã•ã‚ŒãŸæŠ½å‡ºçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        st.warning("æŠ½å‡ºçµæœã‚’è¡¨å½¢å¼ã«å¤‰æ›ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.exception(e)

if "extracted_text" in st.session_state:
    if st.button("å›ºå®šè³‡ç”£ã‚’åˆ¤å®šã™ã‚‹"):
        with st.spinner("å›ºå®šè³‡ç”£ã®æƒ…å ±ã‚’åˆ¤å®šä¸­ï¼ï¼ï¼"):
            document_text = st.session_state.get("edited_extracted_df", None)

            # edited_extracted_dfãŒæœªä¿å­˜ã®å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®extracted_itemsã‚’ä½¿ç”¨
            if document_text is None:
                document_text = st.session_state["extracted_items"]
            elif isinstance(document_text, pd.DataFrame):
                document_text = document_text.to_csv(index=False)

            rag_response = asset_judge(
                user_chat="ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å“ç›®ã”ã¨ã«é‡‘é¡ã€å‹˜å®šç§‘ç›®ã€æ³•å®šè€ç”¨å¹´æ•°ã€æ ¹æ‹ ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚",
                document_text=document_text
            )
            st.session_state["rag_response"] = rag_response

if "rag_response" in st.session_state:
    st.subheader("å›ºå®šè³‡ç”£åˆ¤å®šçµæœ")
    # st.markdown(st.session_state["rag_response"]) 
    # è¡¨å½¢å¼ã«å¤‰æ›ã—ã¦è¡¨ç¤º
    try:
        df = parse_llm_output_to_dataframe(st.session_state["rag_response"])
        # st.subheader("å›ºå®šè³‡ç”£åˆ¤å®šçµæœ")
        edited_df = st.data_editor(df, use_container_width=True, num_rows="dynamic")

        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã€ä¿å­˜ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã—ã¦ã€ä¿å­˜å‡¦ç†ã‚’è¿½åŠ å¯èƒ½
        if st.button("ä¿®æ­£å†…å®¹ã‚’ä¿å­˜"):
            st.session_state["edited_df"] = edited_df
            st.success("ä¿®æ­£å†…å®¹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    except Exception as e:
        st.error("è¡¨å½¢å¼ã§ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡ºåŠ›å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.exception(e)


# --- å°å¸³æ›¸ãè¾¼ã¿ç”¨å‡ºåŠ› ---
if "rag_response" in st.session_state:
    if st.button("å›ºå®šè³‡ç”£å°å¸³ã¸ã®æ›¸ãè¾¼ã¿ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹"):
        # å„ªå…ˆé †ï¼šç·¨é›†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã†ã€‚ãªã‘ã‚Œã°å…ƒã®rag_responseã‹ã‚‰ä½œæˆ
        with st.spinner("å›ºå®šè³‡ç”£å°å¸³ã¸ã®æ›¸ãè¾¼ã¿ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¦ã„ã¾ã™ï¼ï¼ï¼"):
            if "edited_df" in st.session_state:
                df = st.session_state["edited_df"]
                st.info("ç·¨é›†æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
            elif "rag_response" in st.session_state:
                try:
                    df = parse_llm_output_to_dataframe(st.session_state["rag_response"])
                    st.info("å…ƒã®RAGå‡ºåŠ›ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆç·¨é›†ãªã—ï¼‰")
                except Exception as e:
                    st.error("rag_response ã®æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    st.exception(e)
                    df = None
            else:
                st.warning("ç·¨é›†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚‚å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                df = None

            if df is not None:
                final_response = refine_rag_response_from_df(df)
                st.session_state["final_rag_response"] = final_response

                st.markdown("### å›ºå®šè³‡ç”£å°å¸³ç”¨ã®æœ€çµ‚å‡ºåŠ›çµæœ")

                try:
                    # è¡¨å½¢å¼ã§è¡¨ç¤ºï¼†ç·¨é›†å¯èƒ½
                    df = parse_llm_output_to_dataframe(st.session_state["final_rag_response"])
                    edited_final_df = st.data_editor(df, use_container_width=True, num_rows="dynamic")
                    st.session_state["edited_final_df"] = edited_final_df
                except Exception as e:
                    st.error("æœ€çµ‚å‡ºåŠ›ã®è¡¨å½¢å¼å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    st.exception(e)
                    st.text_area("ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºï¼ˆå‚è€ƒï¼‰", final_response, height=400)

# --- ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆæ©Ÿèƒ½ ---
st.markdown("---")
st.header("ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

user_input = st.text_input("ä¸æ˜ç‚¹ã‚ã‚Œã°è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="chat_input")
if st.button("é€ä¿¡"):
    if user_input:
        # ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰
        old_chat = ""
        for speaker, message in st.session_state.chat_history:
            prefix = "ãƒ¦ãƒ¼ã‚¶ãƒ¼: " if speaker == "ãƒ¦ãƒ¼ã‚¶ãƒ¼" else "ãƒœãƒƒãƒˆ: "
            old_chat += f"{prefix}{message}\n"

        # --- ä¿®æ­£æ¸ˆã¿ã® DataFrame ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã† ---
        df_chat_source = st.session_state.get("edited_df")  # â† rag_responseã‚’ç·¨é›†ã—ãŸDataFrame
        if df_chat_source is not None:
            document_text = df_chat_source.to_csv(index=False)
        else:
            document_text = st.session_state.get("rag_response", "")

        # å¿œç­”ç”Ÿæˆ
        with st.spinner("AIãŒå¿œç­”ã‚’ç”Ÿæˆä¸­..."):
            bot_reply = generate_response(user_input, old_chat=old_chat, document_text=document_text)

        st.session_state.chat_history.append(("ãƒ¦ãƒ¼ã‚¶ãƒ¼", user_input))
        st.session_state.chat_history.append(("ãƒœãƒƒãƒˆ", bot_reply))
# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤ºï¼ˆæœ€å¤§å¹…ã§è¡¨ç¤ºï¼‰
for speaker, message in st.session_state.chat_history:
    with st.container():
        if speaker == "ãƒ¦ãƒ¼ã‚¶ãƒ¼":
            st.markdown(
                f'<div style="text-align: left; background-color: #e6f7ff; padding: 8px; border-radius: 8px; margin-bottom: 4px; width:100%;"><b>ğŸ§‘ {speaker}:</b> {message}</div>',
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                f'<div style="text-align: left; background-color: #f6f6f6; padding: 8px; border-radius: 8px; margin-bottom: 4px; width:100%;"><b>ğŸ¤– {speaker}:</b> {message}</div>',
                unsafe_allow_html=True
            )
